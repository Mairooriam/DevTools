{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540b87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyperclip\n",
    "import re\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "import camelot.io as camelot\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47003619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: 'data/contactors.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "CSV_FILE_PATH = \"data/contactors.csv\"\n",
    "\n",
    "# Path to the output SQL file\n",
    "OUTPUT_SQL_FILE = \"output/contactors.sql\"\n",
    "\n",
    "# Table name\n",
    "TABLE_NAME = \"main.contactor_type\"\n",
    "\n",
    "def generate_sql_from_csv():\n",
    "    try:\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "        # Open the output file in write mode\n",
    "        with open(OUTPUT_SQL_FILE, \"w\") as sql_file:\n",
    "            for _, row in df.iterrows():\n",
    "                # Generate the SQL INSERT statement for each row (excluding ID)\n",
    "                sql_statement = f\"\"\"\n",
    "                INSERT INTO {TABLE_NAME} (In_ac1, In_ac3, p_ac1, p_ac3, nc_aux_count, no_aux_count, control_voltage)\n",
    "                VALUES ({row['In_ac1']}, {row['In_ac3']}, {row['p_ac1']}, {row['p_ac3']}, {row['nc_aux_count']}, {row['no_aux_count']}, '{row['control_voltage']}');\n",
    "                \"\"\"\n",
    "                # Write the SQL statement to the file\n",
    "                sql_file.write(sql_statement.strip() + \"\\n\")\n",
    "\n",
    "        print(f\"SQL statements successfully written to {OUTPUT_SQL_FILE}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_sql_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9d9968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 table file(s) in C:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\data\\tables\n",
      "Files: ['circuit_breaker_types.txt', 'contactor_types.txt']\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: circuit_breaker_types.txt\n",
      "============================================================\n",
      "\n",
      "SQL Content:\n",
      "create table main.circuit_breaker_type\n",
      "(\n",
      "    ID     integer\n",
      "        constraint circuit_breaker_type_pk\n",
      "            primary key,\n",
      "    curve  text    not null,\n",
      "    phases integer not null,\n",
      "    \"In\"   integer not null,\n",
      "    Ik     integer not null\n",
      ");\n",
      "\n",
      "create unique index main.circuit_breaker_type_curve_Ik_In_phases_uindex\n",
      "    on main.circuit_breaker_type (curve, Ik, \"In\", phases);\n",
      "\n",
      "\n",
      "\n",
      "Processed Schema:\n",
      "  curve: text\n",
      "  not: null\n",
      "  phases: integer\n",
      "  integer: not\n",
      "  Ik: integer\n",
      "  index: main\n",
      "  circuit_breaker_type_curve_Ik_In_phases_uindex: on\n",
      "\n",
      "Columns: ['curve', 'not', 'phases', 'integer', 'Ik', 'index', 'circuit_breaker_type_curve_Ik_In_phases_uindex']\n",
      "Tab-separated: curve\tnot\tphases\tinteger\tIk\tindex\tcircuit_breaker_type_curve_Ik_In_phases_uindex\t\n",
      "\n",
      "============================================================\n",
      "Processing: contactor_types.txt\n",
      "============================================================\n",
      "\n",
      "SQL Content:\n",
      "create table main.contactor_type\n",
      "(\n",
      "    ID                   integer\n",
      "        constraint circuit_breaker_type_pk\n",
      "            primary key,\n",
      "    In_ac1               real,\n",
      "    In_ac3               real,\n",
      "    p_ac1                real,\n",
      "    p_ac3                integer,\n",
      "    nc_aux_count         integer,\n",
      "    no_aux_count         integer,\n",
      "    control_voltage      text,\n",
      ");\n",
      "\n",
      "Processed Schema:\n",
      "  In_ac1: real\n",
      "  In_ac3: real\n",
      "  p_ac1: real\n",
      "  p_ac3: integer\n",
      "  nc_aux_count: integer\n",
      "  no_aux_count: integer\n",
      "  control_voltage: text\n",
      "\n",
      "Columns: ['In_ac1', 'In_ac3', 'p_ac1', 'p_ac3', 'nc_aux_count', 'no_aux_count', 'control_voltage']\n",
      "Tab-separated: In_ac1\tIn_ac3\tp_ac1\tp_ac3\tnc_aux_count\tno_aux_count\tcontrol_voltage\t\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Processed 2 table(s)\n",
      "============================================================\n",
      "\n",
      "circuit_breaker_types:\n",
      "  Columns (7): curve, not, phases, integer, Ik, index, circuit_breaker_type_curve_Ik_In_phases_uindex\n",
      "\n",
      "contactor_types:\n",
      "  Columns (7): In_ac1, In_ac3, p_ac1, p_ac3, nc_aux_count, no_aux_count, control_voltage\n",
      "\n",
      "'contactor_types' schema copied to clipboard!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class Ctx:\n",
    "    \"\"\"Context manager for file paths with input/output separation\"\"\"\n",
    "    _rootPath: Path = field(default_factory=lambda: Path('.').resolve())\n",
    "    \n",
    "    # Input related (private)\n",
    "    _inputPathStr: str = field(default='data')\n",
    "    _inputFilename: str = field(default=\"input_file.xlsx\")\n",
    "    \n",
    "    # Output related (private)\n",
    "    _outputPathStr: str = field(default=\"output\")\n",
    "    _outputFilename: str = field(default=\"output_file\")\n",
    "    _outputFileExtension: str = field(default=\".xlsx\")\n",
    "    _outputCustomSuffix: Optional[str] = field(default=None)\n",
    "    \n",
    "    \n",
    "    # Read-only properties\n",
    "    @property\n",
    "    def inputDirPath(self) -> Path:\n",
    "        \"\"\"Directory containing input files\"\"\"\n",
    "        return self._rootPath / self._inputPathStr\n",
    "    \n",
    "    @property\n",
    "    def inputFilePath(self) -> Path:\n",
    "        \"\"\"Full path to input file\"\"\"\n",
    "        return self.inputDirPath / self._inputFilename\n",
    "    \n",
    "    @property\n",
    "    def outputDirPath(self) -> Path:\n",
    "        \"\"\"Directory for output files\"\"\"\n",
    "        return self._rootPath / self._outputPathStr\n",
    "    \n",
    "    @property\n",
    "    def outputFilePath(self) -> Path:\n",
    "        \"\"\"Full path to output file with automatic timestamp if file exists\"\"\"\n",
    "        base_name = self._outputFilename + self._outputFileExtension\n",
    "        p = self.outputDirPath / base_name\n",
    "        \n",
    "        if not p.exists():\n",
    "            return p\n",
    "        else:\n",
    "            if self._outputCustomSuffix:\n",
    "                formatted = self._outputCustomSuffix\n",
    "            else:\n",
    "                localTime = time.localtime()\n",
    "                formatted = time.strftime('%Y_%m_%d_%X', localTime)\n",
    "                formatted = formatted.replace(\":\", \"\")\n",
    "            \n",
    "            stem = p.stem  \n",
    "            suffix = p.suffix \n",
    "            new_filename = f\"{stem}_{formatted}{suffix}\"\n",
    "            return p.with_name(new_filename)\n",
    "\n",
    "\n",
    "ctx = Ctx()\n",
    "ctx._inputPathStr = \"data/tables\"\n",
    "\n",
    "# Get all .txt files in data/tables directory\n",
    "tables_dir = ctx.inputDirPath\n",
    "table_files = list(tables_dir.glob(\"*.txt\"))\n",
    "\n",
    "print(f\"Found {len(table_files)} table file(s) in {tables_dir}\")\n",
    "print(f\"Files: {[f.name for f in table_files]}\\n\")\n",
    "\n",
    "ignore_keywords = [\n",
    "    'ID',\n",
    "    'constraint',\n",
    "    'primary',\n",
    "    'create',\n",
    "    'table',\n",
    "    'key'\n",
    "]\n",
    "\n",
    "# Process each file\n",
    "all_schemas = {}\n",
    "\n",
    "for table_file in table_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {table_file.name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Step 1: Read the file\n",
    "    ctx._inputFilename = table_file.name\n",
    "    with open(ctx.inputFilePath, 'r') as f:\n",
    "        read = f.read()\n",
    "    \n",
    "    print(f\"\\nSQL Content:\\n{read}\\n\")\n",
    "    \n",
    "    # Step 2: Extract column definitions\n",
    "    columns = re.findall(r'(\\w+)\\s+(\\w+)', str(read))\n",
    "    \n",
    "    # Step 3: Remove ignored keywords\n",
    "    columns = [col for col in columns if col[0] not in ignore_keywords]\n",
    "    \n",
    "    # Step 4: Convert to a dictionary\n",
    "    schema = {col[0]: col[1] for col in columns}\n",
    "    \n",
    "    # Step 5: Print the processed schema\n",
    "    print(\"Processed Schema:\")\n",
    "    for column, dtype in schema.items():\n",
    "        print(f\"  {column}: {dtype}\")\n",
    "    \n",
    "    # Step 6: Create column list\n",
    "    desired_columns = []\n",
    "    line = \"\"\n",
    "    for column, dtype in schema.items():\n",
    "        desired_columns.append(column)\n",
    "        line += f\"{column}\\t\"\n",
    "    \n",
    "    print(f\"\\nColumns: {desired_columns}\")\n",
    "    print(f\"Tab-separated: {line}\")\n",
    "    \n",
    "    # Store schema\n",
    "    all_schemas[table_file.stem] = {\n",
    "        'schema': schema,\n",
    "        'columns': desired_columns,\n",
    "        'line': line\n",
    "    }\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SUMMARY: Processed {len(all_schemas)} table(s)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for table_name, data in all_schemas.items():\n",
    "    print(f\"\\n{table_name}:\")\n",
    "    print(f\"  Columns ({len(data['columns'])}): {', '.join(data['columns'])}\")\n",
    "\n",
    "# Copy last table's columns to clipboard\n",
    "if all_schemas:\n",
    "    last_table = list(all_schemas.keys())[-1]\n",
    "    pyperclip.copy(all_schemas[last_table]['line'])\n",
    "    print(f\"\\n'{last_table}' schema copied to clipboard!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be6de1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SQL INSERTs for 18 rows...\n",
      "SQL statements successfully written to: C:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\output\\tables\\test_inserts_2026_02_17_22.19.01.sql\n",
      "Total statements: 18\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/contactors_AC3_AND_AC1.xlsx\")\n",
    "\n",
    "# Export the specified columns to a CSV file\n",
    "filtered_df = df[all_schemas['contactor_types']['columns']]\n",
    "\n",
    "# Store the filtered DataFrame in a variable\n",
    "csv_data = filtered_df.to_csv(index=False)\n",
    "\n",
    "# Export the filtered DataFrame to a CSV file\n",
    "filtered_df.to_csv(\"output/tables/filtered_contactors.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get columns from schema\n",
    "columns = list(schema.keys())\n",
    "\n",
    "print(f\"Generating SQL INSERTs for {len(df)} rows...\")\n",
    "\n",
    "# Setup output file\n",
    "ctx._outputFilename = f\"test_inserts\"\n",
    "ctx._outputPathStr = 'output/tables'\n",
    "ctx._outputFileExtension = \".sql\"\n",
    "output_sql_path = ctx.outputFilePath\n",
    "\n",
    "# Generate SQL statements\n",
    "with open(output_sql_path, \"w\") as sql_file:\n",
    "    for idx, row in df.iterrows():\n",
    "        # Build values dynamically based on data types\n",
    "        values = []\n",
    "        for col in columns:\n",
    "            if col not in row:\n",
    "                print(f\"Warning: Column '{col}' not found in CSV, skipping row {idx}\")\n",
    "                continue\n",
    "            \n",
    "            value = row[col]\n",
    "            \n",
    "            # Handle NULL values\n",
    "            if pd.isna(value):\n",
    "                values.append(\"NULL\")\n",
    "            # Handle text types\n",
    "            elif schema[col].lower() in ['text', 'varchar', 'char', 'string']:\n",
    "                # Escape single quotes\n",
    "                escaped_value = str(value).replace(\"'\", \"''\")\n",
    "                values.append(f\"'{escaped_value}'\")\n",
    "            # Handle numeric types\n",
    "            else:\n",
    "                values.append(str(value))\n",
    "        \n",
    "        # Create SQL INSERT statement\n",
    "        columns_str = \", \".join(columns)\n",
    "        values_str = \", \".join(values)\n",
    "        \n",
    "        sql_statement = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str});\"\n",
    "        sql_file.write(sql_statement + \"\\n\")\n",
    "\n",
    "print(f\"SQL statements successfully written to: {output_sql_path}\")\n",
    "print(f\"Total statements: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59ad3865",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPI, HTTPException\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any, Optional\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\fastapi\\__init__.py:7\u001b[39m\n\u001b[32m      3\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m0.129.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstarlette\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m status \u001b[38;5;28;01mas\u001b[39;00m status\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapplications\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPI \u001b[38;5;28;01mas\u001b[39;00m FastAPI\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackground\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackgroundTasks \u001b[38;5;28;01mas\u001b[39;00m BackgroundTasks\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadFile \u001b[38;5;28;01mas\u001b[39;00m UploadFile\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\fastapi\\applications.py:10\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Annotated,\n\u001b[32m      5\u001b[39m     Any,\n\u001b[32m      6\u001b[39m     TypeVar,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mannotated_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m routing\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Default, DefaultPlaceholder\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception_handlers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     http_exception_handler,\n\u001b[32m     14\u001b[39m     request_validation_exception_handler,\n\u001b[32m     15\u001b[39m     websocket_request_validation_exception_handler,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\fastapi\\routing.py:31\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     Annotated,\n\u001b[32m     26\u001b[39m     Any,\n\u001b[32m     27\u001b[39m     TypeVar,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mannotated_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m params\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     ModelField,\n\u001b[32m     34\u001b[39m     Undefined,\n\u001b[32m     35\u001b[39m     lenient_issubclass,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Default, DefaultPlaceholder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\fastapi\\params.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated, Any, Literal\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPIDeprecationWarning\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Example\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AliasChoices, AliasPath\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\fastapi\\exceptions.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated, Any, TypedDict\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mannotated_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, create_model\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstarlette\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPException \u001b[38;5;28;01mas\u001b[39;00m StarletteHTTPException\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstarlette\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WebSocketException \u001b[38;5;28;01mas\u001b[39;00m StarletteWebSocketException\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\pydantic\\__init__.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_migration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getattr_migration\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VERSION, _ensure_pydantic_core_version\n\u001b[32m      8\u001b[39m _ensure_pydantic_core_version()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\pydantic\\_migration.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PydanticDeprecatedSince20\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version_short\n\u001b[32m      8\u001b[39m MOVED_IN_V2 = {\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpydantic.utils:version_info\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpydantic.version:version_info\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpydantic.error_wrappers:ValidationError\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpydantic:ValidationError\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpydantic.generics:GenericModel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpydantic.BaseModel\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     16\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\pydantic\\warnings.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Pydantic-specific warnings.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations \u001b[38;5;28;01mas\u001b[39;00m _annotations\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version_short\n\u001b[32m      7\u001b[39m __all__ = (\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPydanticDeprecatedSince20\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPydanticDeprecatedSince26\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTypedDictExtraConfigWarning\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPydanticDeprecationWarning\u001b[39;00m(\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\35850\\Desktop\\repositories\\DevTools\\image_tables_into_xlsx\\.venv\\Lib\\site-packages\\pydantic\\version.py:7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations \u001b[38;5;28;01mas\u001b[39;00m _annotations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m __pydantic_core_version__\n\u001b[32m      9\u001b[39m __all__ = \u001b[33m'\u001b[39m\u001b[33mVERSION\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mversion_info\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m VERSION = \u001b[33m'\u001b[39m\u001b[33m2.12.5\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1369\u001b[39m     module = sys.modules.get(name, _NEEDS_LOADING)\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n\u001b[32m   1377\u001b[39m _lock_unlock_module(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1342\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1340\u001b[39m     parent_spec._uninitialized_submodules.append(child)\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     module = \u001b[43m_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parent_spec:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:938\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n\u001b[32m    935\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmissing loader\u001b[39m\u001b[33m'\u001b[39m, name=spec.name)\n\u001b[32m    936\u001b[39m         \u001b[38;5;66;03m# A namespace package so do nothing.\u001b[39;00m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:755\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexec_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module):\n\u001b[32m    754\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the module.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     code = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    757\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    758\u001b[39m                           \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:851\u001b[39m, in \u001b[36mSourceLoader.get_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n\u001b[32m    849\u001b[39m source_mtime = \u001b[38;5;28mint\u001b[39m(st[\u001b[33m'\u001b[39m\u001b[33mmtime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytecode_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:950\u001b[39m, in \u001b[36mFileLoader.get_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the data from path as raw bytes.\"\"\"\u001b[39;00m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, (SourceLoader, ExtensionFileLoader)):\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_code\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m file.read()\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any, Optional\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "app = FastAPI(title=\"Database Query API\", version=\"1.0.0\")\n",
    "\n",
    "# Database configuration\n",
    "DATABASE_PATH = \"database.db\"\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    params: Optional[List[Any]] = None\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    data: List[Dict[str, Any]]\n",
    "    columns: List[str]\n",
    "    row_count: int\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Get database connection\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(DATABASE_PATH)\n",
    "        conn.row_factory = sqlite3.Row  # Enable dict-like access\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Database connection failed: {str(e)}\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Database Query API\"}\n",
    "\n",
    "@app.get(\"/tables\")\n",
    "async def get_tables():\n",
    "    \"\"\"Get all table names in the database\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = [row[0] for row in cursor.fetchall()]\n",
    "        return {\"tables\": tables}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.get(\"/tables/{table_name}/schema\")\n",
    "async def get_table_schema(table_name: str):\n",
    "    \"\"\"Get schema information for a specific table\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        schema = cursor.fetchall()\n",
    "        if not schema:\n",
    "            raise HTTPException(status_code=404, detail=f\"Table '{table_name}' not found\")\n",
    "        \n",
    "        columns = []\n",
    "        for col in schema:\n",
    "            columns.append({\n",
    "                \"name\": col[1],\n",
    "                \"type\": col[2],\n",
    "                \"nullable\": not col[3],\n",
    "                \"default\": col[4],\n",
    "                \"primary_key\": bool(col[5])\n",
    "            })\n",
    "        \n",
    "        return {\"table\": table_name, \"columns\": columns}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.get(\"/tables/{table_name}/data\")\n",
    "async def get_table_data(table_name: str, limit: Optional[int] = 100, offset: Optional[int] = 0):\n",
    "    \"\"\"Get data from a specific table with pagination\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # TODO: Replace with actual query - PLACEHOLDER\n",
    "        query = f\"SELECT * FROM {table_name} LIMIT ? OFFSET ?\"\n",
    "        cursor.execute(query, (limit, offset))\n",
    "        \n",
    "        rows = cursor.fetchall()\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        data = [dict(row) for row in rows]\n",
    "        \n",
    "        return QueryResponse(\n",
    "            data=data,\n",
    "            columns=columns,\n",
    "            row_count=len(data)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.post(\"/query\")\n",
    "async def execute_query(request: QueryRequest):\n",
    "    \"\"\"Execute a custom SQL query\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # TODO: Add your custom queries here - PLACEHOLDER\n",
    "        if request.params:\n",
    "            cursor.execute(request.query, request.params)\n",
    "        else:\n",
    "            cursor.execute(request.query)\n",
    "        \n",
    "        # Handle SELECT queries\n",
    "        if request.query.strip().upper().startswith('SELECT'):\n",
    "            rows = cursor.fetchall()\n",
    "            columns = [description[0] for description in cursor.description]\n",
    "            data = [dict(row) for row in rows]\n",
    "            \n",
    "            return QueryResponse(\n",
    "                data=data,\n",
    "                columns=columns,\n",
    "                row_count=len(data)\n",
    "            )\n",
    "        else:\n",
    "            # Handle INSERT, UPDATE, DELETE queries\n",
    "            conn.commit()\n",
    "            return {\"message\": \"Query executed successfully\", \"rows_affected\": cursor.rowcount}\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.get(\"/contactors\")\n",
    "async def get_contactors():\n",
    "    \"\"\"Get all contactors - PLACEHOLDER QUERY\"\"\"\n",
    "    # TODO: Replace with your actual contactor query\n",
    "    query = \"SELECT * FROM contactor_type LIMIT 50\"\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        data = [dict(row) for row in rows]\n",
    "        \n",
    "        return QueryResponse(\n",
    "            data=data,\n",
    "            columns=columns,\n",
    "            row_count=len(data)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.get(\"/contactors/{contactor_id}\")\n",
    "async def get_contactor_by_id(contactor_id: int):\n",
    "    \"\"\"Get specific contactor by ID - PLACEHOLDER QUERY\"\"\"\n",
    "    # TODO: Replace with your actual contactor by ID query\n",
    "    query = \"SELECT * FROM contactor_type WHERE id = ?\"\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query, (contactor_id,))\n",
    "        row = cursor.fetchone()\n",
    "        \n",
    "        if not row:\n",
    "            raise HTTPException(status_code=404, detail=f\"Contactor with ID {contactor_id} not found\")\n",
    "        \n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        data = dict(row)\n",
    "        \n",
    "        return {\"contactor\": data}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# PLACEHOLDER ENDPOINTS - Add your specific queries here\n",
    "@app.get(\"/custom/query1\")\n",
    "async def custom_query_1():\n",
    "    \"\"\"Custom query placeholder 1\"\"\"\n",
    "    # TODO: Add your custom query logic here\n",
    "    query = \"SELECT COUNT(*) as total FROM sqlite_master WHERE type='table'\"\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchone()\n",
    "        return {\"result\": dict(result)}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@app.get(\"/custom/query2\")\n",
    "async def custom_query_2():\n",
    "    \"\"\"Custom query placeholder 2\"\"\"\n",
    "    # TODO: Add your custom query logic here\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "BASE_URL = \"http://localhost:3000/api/circuit-breaker-types\"\n",
    "\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "\n",
    "df = pd.DataFrame(response)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "BASE_URL = \"http://localhost:3000/api/circuit-breaker-types\"\n",
    "import time\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def map_to_order_number(row) -> str:\n",
    "    order_number = \"A9F0\"\n",
    "    match row['curve']:\n",
    "        case 'B':\n",
    "            order_number += \"3\"\n",
    "        case 'C':\n",
    "            order_number += \"4\"\n",
    "\n",
    "    match row['phases']:\n",
    "        case 1:\n",
    "            order_number += \"1\"\n",
    "        case 2:\n",
    "            order_number += \"2\"\n",
    "        case 3:\n",
    "            order_number += \"3\"\n",
    "\n",
    "    order_number += str(row['In']).zfill(2)\n",
    "    return order_number\n",
    "    \n",
    "\n",
    "df['order_number'] = df.apply(map_to_order_number, axis=1)\n",
    "\n",
    "columns = [\n",
    "    \"part_type\", \"manufacturer_id\", \"order_number\", \"sahkonumero\",\n",
    "    \"price\", \"description\", \"created_date\", \"is_active\", \"type_id\"\n",
    "]\n",
    "\n",
    "test = pd.read_excel(\"output/processed_circuit_breakers.xlsx\")\n",
    "test.rename(columns={test.columns[0]: \"order_number\"}, inplace=True)\n",
    "print(test.columns[0])\n",
    "part_base_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(part_base_df, test, on=\"order_number\", how=\"right\")\n",
    "\n",
    "part_base_df['type_id'] = df['ID']\n",
    "part_base_df['manufacturer_id'] = 2\n",
    "part_base_df['order_number'] = df['order_number']\n",
    "part_base_df['sahkonumero'] = merged_df['sahkonumero_y']\n",
    "part_base_df['price'] = 9999\n",
    "part_base_df['description'] = merged_df['description_y']\n",
    "part_base_df['part_type'] = 'circuit_breaker'\n",
    "part_base_df['is_active'] = 1\n",
    "# part_base_df['created_date'] = time.localtime()\n",
    "TABLE_NAME = \"parts_base\"\n",
    "sql_queries = \"\"\n",
    "for _, row in part_base_df.iterrows():\n",
    "    # Dynamically build the VALUES part of the query\n",
    "    values = []\n",
    "    for col in part_base_df.columns:\n",
    "        value = row[col]\n",
    "        if pd.isna(value):  # Handle NULL values\n",
    "            values.append(\"NULL\")\n",
    "        elif isinstance(value, str):  # Handle strings\n",
    "            values.append(f\"'{value.replace('\\'', '\\'\\'')}'\")  # Escape single quotes\n",
    "        else:  # Handle numbers\n",
    "            values.append(str(value))\n",
    "    \n",
    "    # Construct the SQL query\n",
    "    columns_str = \", \".join(part_base_df.columns)\n",
    "    values_str = \", \".join(values)\n",
    "    sql_query = f\"INSERT INTO {TABLE_NAME} ({columns_str}) VALUES ({values_str});\"\n",
    "    \n",
    "    # Append the query to the string\n",
    "    sql_queries += sql_query + \"\\n\"\n",
    "\n",
    "# Copy the generated SQL queries to the clipboard\n",
    "pyperclip.copy(sql_queries)\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df2 = pd.read_excel('output/processed_circuit_breakers.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_excel(\"data/circuit_breakers.xlsx\")\n",
    "\n",
    "## A9F03101\tiC60N johdonsuojak 1P B 1A 6kA\t1\t32 580 01\tB\n",
    "\n",
    "#split description \n",
    "str1 = \"iC60N johdonsuojak 1P B 1A 6kA\"\n",
    "\n",
    "def extract_decimal(cell: str):\n",
    "    split = cell.split()\n",
    "    numbers = re.findall(r'\\d+', str(split[4])) if len(split) > 4 else []\n",
    "    if len(numbers) == 2:\n",
    "        decimal_str = f\"{numbers[0]}.{numbers[1]}\"\n",
    "        try:\n",
    "            return float(decimal_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    elif len(numbers) == 1:\n",
    "        try:\n",
    "            return int(numbers[0])\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['in'] = df['description'].apply(extract_decimal)\n",
    "\n",
    "\n",
    "columns = [\n",
    "    \"part_type\", \"manufacturer_id\", \"order_number\", \"sahkonumero\",\n",
    "    \"price\", \"description\", \"created_date\", \"is_active\", \"type_id\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_URL = \"http://localhost:3000/api/circuit-breaker-types\"\n",
    "\n",
    "\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "data = response.json()\n",
    "database = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc91d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_number\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 1.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 1, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 2, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 3, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'B', 4, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 0.5, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 1.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 3.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 1, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 0.5, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 1.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 3.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 2, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 0.5, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 1.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 3.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 3, 63.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 0.5, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 1.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 2.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 3.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 4.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 6.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 10.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 16.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 20.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 25.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 32.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 40.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 50.0, 6000);\n",
      "INSERT INTO circuit_breaker_types (ID, curve, phases, \"In\", Ik) VALUES (NULL, 'C', 4, 63.0, 6000);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "BASE_URL = \"http://localhost:3000/api/circuit-breaker-types\"\n",
    "import time\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def map_to_order_number(row) -> str:\n",
    "    order_number = \"A9F0\"\n",
    "    match row['curve']:\n",
    "        case 'B':\n",
    "            order_number += \"3\"\n",
    "        case 'C':\n",
    "            order_number += \"4\"\n",
    "\n",
    "    match row['phases']:\n",
    "        case 1:\n",
    "            order_number += \"1\"\n",
    "        case 2:\n",
    "            order_number += \"2\"\n",
    "        case 3:\n",
    "            order_number += \"3\"\n",
    "\n",
    "    order_number += str(int(row['In'])).zfill(2)\n",
    "    return order_number\n",
    "    \n",
    "\n",
    "df['order_number'] = df.apply(map_to_order_number, axis=1)\n",
    "\n",
    "columns = [\n",
    "    \"part_type\", \"manufacturer_id\", \"order_number\", \"sahkonumero\",\n",
    "    \"price\", \"description\", \"created_date\", \"is_active\", \"type_id\"\n",
    "]\n",
    "\n",
    "\n",
    "test = pd.read_excel(\"output/processed_circuit_breakers.xlsx\")\n",
    "test.rename(columns={test.columns[0]: \"order_number\"}, inplace=True)\n",
    "print(test.columns[0])\n",
    "\n",
    "\n",
    "merged_df = pd.merge(df, test, on=\"order_number\", how=\"right\")\n",
    "\n",
    "columns2 = [\n",
    "    \"ID\",\n",
    "    \"curve\",\n",
    "    \"phases\",\n",
    "    \"In\",\n",
    "    \"Ik\"\n",
    "]\n",
    "\n",
    "temp = pd.DataFrame(columns=columns2)\n",
    "temp['curve'] = merged_df['curve_y']\n",
    "temp['phases'] = merged_df['phases_y']\n",
    "temp['In'] = merged_df['numbers']\n",
    "temp['Ik'] = 6000\n",
    "table_name = \"circuit_breaker_types\"\n",
    "\n",
    "# Initialize an empty string to store the SQL statements\n",
    "sql_statements = \"\"\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for _, row in temp.iterrows():\n",
    "    # Extract values for each column\n",
    "    values = [\n",
    "        \"NULL\" if pd.isna(row[\"ID\"]) else row[\"ID\"],  # Handle NULL for ID\n",
    "        f\"'{row['curve']}'\",  # Text values need to be quoted\n",
    "        row[\"phases\"],\n",
    "        row[\"In\"],\n",
    "        row[\"Ik\"]\n",
    "    ]\n",
    "    \n",
    "    # Convert the values list to a comma-separated string\n",
    "    values_str = \", \".join(map(str, values))\n",
    "    \n",
    "    # Create the SQL INSERT statement\n",
    "    sql_statement = f\"INSERT INTO {table_name} (ID, curve, phases, \\\"In\\\", Ik) VALUES ({values_str});\"\n",
    "    \n",
    "    # Append the statement to the collection\n",
    "    sql_statements += sql_statement + \"\\n\"\n",
    "\n",
    "# Print or save the generated SQL statements\n",
    "print(sql_statements)\n",
    "pyperclip.copy(sql_statements)\n",
    "nan_id_rows = merged_df[merged_df['ID'].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-table-into-xlsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
